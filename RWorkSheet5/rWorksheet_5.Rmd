---
title: "rWorksheet_5"
author: "Rey Angelo Calopez BSIT 2-C"
date: "2023-12-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
1. Create a data frame for the table below. Show your solution.
a. Compute the descriptive statistics using different packages (Hmisc and pastecs).
Write the codes and its result.
```{r}
StudentScore <- data.frame(Student = c(1,2,3,4,5,6,7,8,9,10),
                           PreTest = c(55,54,47,57,51,61,57,54,63,58),
                           PostTest = c(61,60,56,63,56,63,59,56,62,61))

StudentScore

#a.Compute the descriptive statistics using different packages (Hmisc and pastecs).
library(Hmisc)
library(pastecs)


HmiscStats <- describe(StudentScore[,c("PreTest","PostTest")])
HmiscStats

# Calculate descriptive statistics using pastecs
pastecsStats <- apply(StudentScore[,c('PreTest','PostTest')], 2, function(x) summary(x))
pastecsStats


```
2. The Department of Agriculture was studying the effects of several levels of a fertilizer
on the growth of a plant. For some analyses, it might be useful to convert the fertilizer
levels to an ordered factor.
```{r}
library(dplyr)

fertilizerLevels <- c(10,10,10, 20,20,50,10,20,10,50,20,50,20,10)

orderedFactor <- factor(fertilizerLevels, levels = unique(fertilizerLevels))

basicStats <- summary(orderedFactor)
basicStats
```
3. Abdul Hassan, president of Floor Coverings Unlimited, has asked you to study the ex-
ercise levels undertaken by 10 subjects were “l”, “n”, “n”, “i”, “l” , “l”, “n”,

“n”, “i”, “l” ; n=none, l=light, i=intense
a. What is the best way to represent this in R?

```{r}
excerciseLevels <- c("n", "l", "n", "n", "l", "l", "n", "n", "i", "l")

ExerciseFactor <- factor(excerciseLevels, levels = c("n","l","i"))


basic_stats <- summary(ExerciseFactor)
basic_stats
```
4. Sample of 30 tax accountants from all the states and territories of Australia and their
individual state of origin is specified by a character vector of state mnemonics as:
state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")
a. Apply the factor function and factor level. Describe the results.
```{r}
state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")
stateFactor <- factor(state)
stateFactor

summaryState <- summary(stateFactor)
summaryState

```
5. From #4 - continuation:
• Suppose we have the incomes of the same tax accountants in another vector (in suitably
large units of money)
incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)
a. Calculate the sample mean income for each state we can now use the special function
tapply():
Example: giving a means vector with the components labelled by the levels
incmeans <- tapply(incomes, statef, mean)
Note: The function tapply() is used to apply a function, here mean(), to each group
of components of the first argument, here incomes, defined by the levels of the second
component, here state 2
```{r}
incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)

meanIncome <- tapply(incomes, stateFactor, mean)
meanIncome

```
b.
6.Calculate the standard errors of the state income means (refer again to number 3)
stdError <- function(x) sqrt(var(x)/length(x))
Note: After this assignment, the standard errors are calculated by:
incster <- tapply(incomes, statef, stdError)
a. What is the standard error? Write the codes.
```{r}
stdError <- function(x) sqrt(var(x)/length(x))
incster <- tapply(incomes, state, stdError)
standardError <- tapply(incomes, stateFactor, stdError)
standardError
```
7. Use the titanic dataset.
a. subset the titatic dataset of those who survived and not survived. Show the codes
and its result.
```{r}

# Install and load the 'titanic' package if not already installed
install.packages("titanic")
library(titanic)

# Load the Titanic dataset
data("titanic_train")
titanic_data <- titanic_train

# Subset the dataset into those who survived and those who did not survive
survived_data <- subset(titanic_data, Survived == 1)
not_survived_data <- subset(titanic_data, Survived == 0)

# Show the first few rows of the resulting datasets
head(survived_data)
head(not_survived_data)

```
8. The data sets are about the breast cancer Wisconsin. The samples arrive periodically
as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronologi https://drive.google.com/file/d/16MFLoehCgx2MJuNSAuB2CsBy6eDIIr-
u/view?usp=drive_link)

a. describe what is the dataset all about.
Ans. This data set shows all levels related to breast cancer like clump thickness, size, shape and many more.

d. Compute the descriptive statistics using different packages. Find the values of:
d.1 Standard error of the mean for clump thickness.
d.2 Coefficient of variability for Marginal Adhesion.
d.3 Number of null values of Bare Nuclei.
d.4 Mean and standard deviation for Bland Chromatin
d.5 Confidence interval of the mean for Uniformity of Cell Shape


```{r}
library(readr)
library(rcompanion)
breastcancer_wisconsin <- read_csv("breastcancer_wisconsin.csv",col_types = cols(
  id = col_double(),
  clump_thickness = col_double(),
  size_uniformity = col_double(),
  shape_uniformity = col_double(),
  marginal_adhesion = col_double(),
  epithelial_size = col_double(),
  bare_nucleoli = col_character(),
  bland_chromatin = col_double(),
  normal_nucleoli = col_double(),
  mitoses = col_double(),
  class = col_double()
))
breastcancer_wisconsin

#d.1 Standard error of the mean for clump thickness.
clump_thickness <- sd(breastcancer_wisconsin$clump_thickness) / sqrt(length(breastcancer_wisconsin$clump_thickness))
cat("d.1 Standard Error of the Mean for Clump Thickness:", clump_thickness, "\n")

# d.2 Coefficient of variability for Marginal Adhesion.
marginal_adhesion <- sd(breastcancer_wisconsin$marginal_adhesion) / mean(breastcancer_wisconsin$marginal_adhesion) 
cat("d.2 Coefficient of Variability for Marginal Adhesion:", marginal_adhesion, "%\n")

# d.3 Number of null values of Bare Nuclei.
values_bare_nuclei <- sum(is.na(breastcancer_wisconsin$bare_nucleoli))
cat("d.3 Number of Null Values in Bare Nuclei:", values_bare_nuclei, "\n")

# d.4 Mean and standard deviation for Bland Chromatin.
mean_bland_chromatin <- mean(breastcancer_wisconsin$bland_chromatin)
mean_bland_chromatin
sd_bland_chromatin <- sd(breastcancer_wisconsin$bland_chromatin)
cat("d.4 Mean for Bland Chromatin:", mean_bland_chromatin, "\n")
cat("   Standard Deviation for Bland Chromatin:", sd_bland_chromatin, "\n")


# d.5 Confidence interval of the mean for Uniformity of Cell Shape.
uniformity_of_cell_shape <- t.test(breastcancer_wisconsin$shape_uniformity, conf.level = 0.95)$conf.int
cat("d.5 Confidence Interval for the Mean of Uniformity of Cell Shape:", uniformity_of_cell_shape, "\n")


```
9. Export the data abalone to the Microsoft excel file. Copy the codes.
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
view(abalone)
head(abalone)
summary(abalone)
```{r}
#install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")

data(abalone)
#View(abalone)
head(abalone)
summary(abalone)

#export

library(xlsx)

#write.xlsx(abalone, "abalone.xlsx")
```